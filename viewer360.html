<!DOCTYPE html>
<html lang='en'>
<head>
<title>Web VR Video 360</title>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, shrink-to-fit=no'>
<meta name='mobile-web-app-capable' content='yes'>
<meta name='apple-mobile-web-app-capable' content='yes' />
<meta name='apple-mobile-web-app-status-bar-style' content='black-translucent' />
<link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css'>
<style>
html, body {
	width: 100%;
	height: 100%;
	background-color: #000;
	color: #fff;
	margin: 0px;
	padding: 0;
	overflow: hidden;
}

canvas {
	position: absolute;
	top: 0;
}
#fullScreenContainer {
	width: 100%;
	height: 100%;
	position: relative;
}

#buttons {
	position: absolute;
	bottom: 0;
	right: 0;
	z-index: 1;
	/*to prevent mouse selection of the button*/
	user-select: none;
	-webkit-user-select: none;
}
#buttons i {
	color: #ccc;
	font-size: 150%;
	margin-bottom: 0.4em;
	margin-right: 0.4em;
}
#buttons i:hover {
	color: #fff;
	text-shadow: 0px 0px 5px lightblue, 0px 0px 10px lightblue;
	cursor: pointer;
}
</style>
</head>

<body>

	<div id='fullScreenContainer'>
		<div style='position:absolute; top: 10px; width: 100%; text-align: center; font-family: Monospace; font-weight: bold; padding;color:grey; z-index: 1000;'>
			Viewer of 360 content - using webvr and three.js
			<br/>
			<a href='javascript:void(0)' onclick='switchSource("videoMono")' style='color: grey'>video 360</a>
			<a href='javascript:void(0)' onclick='switchSource("imageMono")' style='color: grey'>image 360</a>
		</div>
		<div id='buttons'>
			<i class='fa fa-arrows-alt' id='fullscreenButton'></i>
			<i class='fa fa-eye' id='vrButton'></i>
			<i class='fa fa-star' id='resetButton' title='reset position'></i>
		</div>
	</div>
</body>

<script>
WebVRConfig = {
	BUFFER_SCALE: 0.5,
};

document.addEventListener('touchmove', function(event) {
	event.preventDefault();
});
</script>

<!-- three.js library -->
<script src='vendor/three.js/build/three.js'></script>

<!-- VRControls.js applies the WebVR transformations to a three.js camera object. -->
<script src='vendor/three.js/examples/js/controls/VRControls.js'></script>

<!-- VREffect.js handles stereo camera setup and rendering.  -->
<script src='vendor/three.js/examples/js/effects/VREffect.js'></script>
<!-- <script src='vendor/three.js/examples/js/effects/VREffect-fromweb.js'></script> -->

<!-- A polyfill for the WebVR API.  -->
<script src='vendor/webvr-polyfill.js'></script>


<script>
var onRenderFcts = []

// Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
// Only enable it if you actually need to.
var renderer = new THREE.WebGLRenderer({antialias: false});
renderer.setPixelRatio(Math.floor(window.devicePixelRatio));

// Append the canvas element created by the renderer to fullScreenContainer
document.querySelector('#fullScreenContainer').appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);

// Apply VR headset positional data to camera.
var controls = new THREE.VRControls(camera);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(window.innerWidth, window.innerHeight);

// Get the VRDisplay and save it for later.
var vrDisplay = null;
navigator.getVRDisplays().then(function(displays) {
	if (displays.length > 0) {
		vrDisplay = displays[0];
	}
	
	if( vrDisplay !== null ){
		if( vrDisplay.capabilities.canPresent !== true ){
			document.querySelector('#vrButton').style.display = 'none'
		}
	}
});

// Request animation frame loop function
var lastRender = 0;
function animate(timestamp) {
	var delta = Math.min(timestamp - lastRender, 500);
	lastRender = timestamp;
	
	// Apply rotation to cube mesh
	onRenderFcts.forEach(function(onRenderFct){
		onRenderFct(delta)
	})
	
	// Update VR headset position and apply to camera.
	controls.update();
	
	// Render the scene.
	effect.render(scene, camera);
	
	// Keep looping.
	requestAnimationFrame(animate);
}

// Kick off animation loop.
requestAnimationFrame(animate);

//////////////////////////////////////////////////////////////////////////////////
//		Comments
//////////////////////////////////////////////////////////////////////////////////

function onResize() {
	console.log('Resizing to %s x %s.', window.innerWidth, window.innerHeight);
	effect.setSize(window.innerWidth, window.innerHeight);
	camera.aspect = window.innerWidth / window.innerHeight;
	camera.updateProjectionMatrix();
}

// Resize the WebGL canvas when we resize and also when we change modes.
window.addEventListener('resize', onResize);
window.addEventListener('vrdisplaypresentchange', function onVRDisplayPresentChange() {
	console.log('onVRDisplayPresentChange');
	onResize();
});

// Button click handlers.
document.querySelector('#fullscreenButton').addEventListener('click', function() {
	var domElement = document.querySelector('#fullScreenContainer')
	enterFullscreen(domElement);
});
document.querySelector('#vrButton').addEventListener('click', function() {
	vrDisplay.requestPresent([{source: renderer.domElement}]);
});
document.querySelector('#resetButton').addEventListener('click', function() {
	vrDisplay.resetPose();
});

renderer.domElement.addEventListener('click', function(event){
	var element = renderer.domElement
	// check it is the proper click
	if( event.target !== element )	return
	if( vrDisplay.displayName !== "Mouse and Keyboard VRDisplay (webvr-polyfill)")	return
	// Ask the browser to lock the pointer
	element.requestPointerLock = element.requestPointerLock || element.mozRequestPointerLock || element.webkitRequestPointerLock;
	if ( /Firefox/i.test( navigator.userAgent ) ) {
		var fullscreenchange = function ( event ) {
			if ( document.fullscreenElement === element || document.mozFullscreenElement === element || document.mozFullScreenElement === element ) {
				document.removeEventListener( 'fullscreenchange', fullscreenchange );
				document.removeEventListener( 'mozfullscreenchange', fullscreenchange );
				element.requestPointerLock();
			}
		};
		document.addEventListener( 'fullscreenchange', fullscreenchange, false );
		document.addEventListener( 'mozfullscreenchange', fullscreenchange, false );
		element.requestFullscreen = element.requestFullscreen || element.mozRequestFullscreen || element.mozRequestFullScreen || element.webkitRequestFullscreen;
		element.requestFullscreen();
	} else {
		element.requestPointerLock();
	}
})

function enterFullscreen (element) {
	if (element.requestFullscreen) {
		element.requestFullscreen();
	} else if (element.mozRequestFullScreen) {
		element.mozRequestFullScreen();
	} else if (element.webkitRequestFullscreen) {
		element.webkitRequestFullscreen();
	} else if (element.msRequestFullscreen) {
		element.msRequestFullscreen();
	}
}

//////////////////////////////////////////////////////////////////////////////
//		Code Separator
//////////////////////////////////////////////////////////////////////////////

if( location.hash === '#imageMono' )	switchSource('imageMono')
if( location.hash === '#videoMono' )	switchSource('videoMono')
if( location.hash === '' )		switchSource('imageMono')

var container = null

function switchSource(sourceType){
	if( container )	container.parent.remove(container)
	
	location.hash = '#'+sourceType
	
	if( sourceType === 'imageMono'){
		container = createImageMono()
		scene.add(container)
	}else if( sourceType === 'videoMono'){
		container = createVideoMono()
		scene.add(container)
	}else{
		console.assert(false)
	}
}

document.addEventListener('sourceChange', function onSourceChange(event){
	console.log('sourceChange', event)
})

function createImageMono(){	
	document.dispatchEvent(new CustomEvent('sourceChange', { detail : {sourceType: 'imageMono'}}));

	var geometry = new THREE.SphereGeometry( 500, 60, 40 );
	geometry.scale( - 1, 1, 1 );

	var material = new THREE.MeshBasicMaterial( {
		map: new THREE.TextureLoader().load( 'images/panorama.jpg' )
		// map: new THREE.TextureLoader().load( 'images/IMG_0405.JPG' )
	} );
	material.map.minFilter = THREE.LinearFilter;
	material.map.format = THREE.RGBFormat;

	var mesh = new THREE.Mesh( geometry, material );
	return mesh;
}

function createVideoMono(){
	var geometry = new THREE.SphereBufferGeometry( 500, 60, 40 );
	geometry.scale( - 1, 1, 1 );

	var video = document.createElement( 'video' );
	video.width = 640;
	video.height = 360;
	video.autoplay = true;
	video.loop = true;
	// video.src = "videos/pano.webm";
	video.src = "videos/pano.mp4";
	var texture = new THREE.VideoTexture( video );
	texture.minFilter = THREE.LinearFilter;
	texture.format = THREE.RGBFormat;
	var material   = new THREE.MeshBasicMaterial( { map : texture } );
	mesh = new THREE.Mesh( geometry, material );

	document.dispatchEvent(new CustomEvent('sourceChange', { detail : {sourceType: 'videoMono'}}));

	function onClick(){
		video.play()
		document.body.removeEventListener('click', onClick)
	}
	document.body.addEventListener('click', onClick)

	document.addEventListener('sourceChange', function onSourceChange(event){
		video.pause()
		document.removeEventListener('sourceChange', onSourceChange)
		document.body.removeEventListener('click', onClick)
	})


	return mesh;
}
</script></html>
